{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "superior-tomorrow",
   "metadata": {},
   "source": [
    "## Actor Critic with GAE Implementation:\n",
    "\n",
    "Here I will solve the Reacher 20, novis environment (from udacity second project). The reacher environment can be found [here](https://s3-us-west-1.amazonaws.com/udacity-drlnd/P2/Reacher/Reacher_Linux_NoVis.zip).\n",
    "\n",
    "Source: [https://github.com/higgsfield/RL-Adventure-2/blob/master/2.gae.ipynb](https://github.com/higgsfield/RL-Adventure-2/blob/master/2.gae.ipynb)\n",
    "\n",
    "A2C with GAE basic pseudocode: \n",
    "- The agent takes NUM_STEPS in the environment, collecting rewards, state values, log probability of actions (log of policy) and terminal states\n",
    "- Using the collected values, the agent computes GAE values\n",
    "- advantages is calculated using: gae_returns - values \n",
    "- actor loss is calculated using: -(log_probs * advantages)  \n",
    "- critic loss is calculated using: advantages ** 2\n",
    "- losses are backpropagated to train the network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suited-inflation",
   "metadata": {},
   "source": [
    "### 1. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "automated-longer",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.distributions import Categorical\n",
    "from torch.distributions.normal import Normal\n",
    "from unityagents import UnityEnvironment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "corrected-profile",
   "metadata": {},
   "source": [
    "### 2. Define Policy Network\n",
    "\n",
    "Very simple fully connected neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "oriented-drawing",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(m):\n",
    "    \"\"\" Initializes the weights and bias values of the Linear layers in the network \"\"\"\n",
    "\n",
    "    if isinstance(m, nn.Linear):\n",
    "        nn.init.normal_(m.weight, mean=0., std=0.1)\n",
    "        nn.init.constant_(m.bias, 0.1)\n",
    "\n",
    "\n",
    "class A2CNetwork(nn.Module):\n",
    "    def __init__(self, state_size, action_size, std=0.0):\n",
    "        super(A2CNetwork, self).__init__()\n",
    "\n",
    "        # the critic network, it's output represents the state value for baseline\n",
    "        self.critic = nn.Sequential(\n",
    "            nn.Linear(state_size, 1024),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(1024, 128),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(128, 1)\n",
    "        )\n",
    "\n",
    "        # the actor network\n",
    "        self.actor = nn.Sequential(\n",
    "            nn.Linear(state_size, 1024),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(1024, 256),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(256, action_size),\n",
    "        )\n",
    "        \n",
    "        # value of log_std will also be updated by gradient update\n",
    "        self.log_std = nn.Parameter(torch.ones(1, action_size) * std)\n",
    "\n",
    "        self.apply(init_weights)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\" Returns distributions of actions and state value for input state \"\"\"\n",
    "\n",
    "        value = self.critic(x)\n",
    "        mu = torch.tanh(self.actor(x))\n",
    "\n",
    "        # calculating the standard deviation for the normal distribution\n",
    "        # if self.log_std is zeros tensor, then std is ones tensor\n",
    "        std = self.log_std.exp().expand_as(mu)\n",
    "\n",
    "        # creating a normal distribution using mu and std\n",
    "        # using this normal distribution (dist), the action value will be sampled\n",
    "        dist = Normal(mu, std)\n",
    "\n",
    "        return dist, value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quick-handbook",
   "metadata": {},
   "source": [
    "### 3. Define Agent "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "mobile-agenda",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Hyper-parameters:\n",
    "NUM_STEPS = 10  # number of steps in rollout\n",
    "LEARNING_RATE = 1e-4  # learning rate for the optimizer\n",
    "OPTIMIZER_EPS = 1e-3  # default eps value for optimizer might be too low for converging\n",
    "\n",
    "\n",
    "class ReacherAgent:\n",
    "    \"\"\" The ReacherAgent class is responsible for interacting with the reacher environment and\n",
    "        teaching the neural network (model) to take appropriate actions based on states\n",
    "\n",
    "        This class is based on codes found here: \n",
    "        https://github.com/higgsfield/RL-Adventure-2/blob/master/2.gae.ipynb\n",
    "        \"\"\"\n",
    "\n",
    "    def __init__(self, num_inputs, num_outputs, env, brain_name, num_agents):\n",
    "        \"\"\"Initialize an ReacherAgent object.\n",
    "\n",
    "        Params\n",
    "        ======\n",
    "            num_inputs (int): dimension of each state\n",
    "            num_outputs (int): dimension of each action\n",
    "            env: the reacher environment object\n",
    "            brain_name: reacher environment brain name\n",
    "            num_agents: number of agents in reacher environment\n",
    "        \"\"\"\n",
    "\n",
    "        self.model = A2CNetwork(num_inputs, num_outputs).to(device)\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=LEARNING_RATE, eps=OPTIMIZER_EPS)\n",
    "        self.env = env\n",
    "        self.brain = brain_name\n",
    "        self.num_agents = num_agents\n",
    "\n",
    "        # Initial state is stored in self.state. The states are normalized by dividing by 10.0\n",
    "        env_info = self.env.reset(train_mode=True)[self.brain]\n",
    "        self.state = env_info.vector_observations / 10.0\n",
    "\n",
    "        self.scores = np.zeros(self.num_agents)  # scores keeps track of the env rewards\n",
    "\n",
    "    def compute_gae(self, next_value, rewards, masks, values, gamma=0.99, tau=0.95):\n",
    "        \"\"\" Returns the GAE (Generalized advantage estimation) value for a rollout, check \n",
    "        https://raw.githubusercontent.com/fahimfss/ProjectReacher/master/images_videos/compute_gae.png \n",
    "        for understanding how this method works\n",
    "\n",
    "        Params\n",
    "        ======\n",
    "            next_value: state value of the the last state in rollout\n",
    "            rewards: reward values during rollout\n",
    "            masks: terminal state masks of each state in rollout (1 means that state is terminal)\n",
    "            values: state values of each state in rollout\n",
    "            gamma: discount rate\n",
    "            tau: exponentially decaying factor for calculating GAE\n",
    "        \"\"\"\n",
    "\n",
    "        values = values + [next_value]\n",
    "        gae = 0\n",
    "        returns = []\n",
    "        for step in reversed(range(len(rewards))):\n",
    "            delta = rewards[step] + gamma * values[step + 1] * masks[step] - values[step]\n",
    "            gae = delta + gamma * tau * masks[step] * gae\n",
    "            returns.insert(0, gae + values[step])\n",
    "        return returns\n",
    "\n",
    "    def step(self):\n",
    "        \"\"\" step method does a NUM_STEPS rollout in the environment and updates the neural network (model)\n",
    "\n",
    "            :returns\n",
    "            The episode number and the mean score of agents in that episode if an episode ends in rollout\n",
    "        \"\"\"\n",
    "\n",
    "        log_probs = []          # array to store log probabilities of each action in rollout\n",
    "        values = []             # array to store state values (from model) of each state in rollout\n",
    "        rewards = []            # array to store reward values for each step in rollout (provided by env)\n",
    "        masks = []              # array to store terminal state flags for each state in rollout\n",
    "        # Size of all four arrays after rollout: [NUM_STEPS, NUM_AGENTS]\n",
    "\n",
    "        entropy = 0                         # entropy term to encourage exploration\n",
    "\n",
    "        ret = None\n",
    "\n",
    "        for _ in range(NUM_STEPS):          # NUM_STEPS rollout\n",
    "\n",
    "            # Select action using the current state\n",
    "            state = torch.FloatTensor(self.state).to(device)\n",
    "            # the model returns a normal distribution for action value, and V(s)\n",
    "            dist, value = self.model(state)     \n",
    "            # action is sampled from the distribution and clipped in range [-1, 1]\n",
    "            action = dist.sample().clamp(-1, 1)   \n",
    "            action_np = action.cpu().numpy()\n",
    "\n",
    "            env_info = self.env.step(action_np)[self.brain]      # action is applied in the env\n",
    "            next_state = env_info.vector_observations / 10.0     # next_state is normalized by dividing by 10.0\n",
    "            reward = np.asarray(env_info.rewards) * 20.0         # rewards are amplified by multiplying by 20\n",
    "            done = np.array(env_info.local_done, dtype=int)      # done (terminal) flags are created\n",
    "\n",
    "            self.scores += env_info.rewards      # actual reward values are added to score\n",
    "\n",
    "            log_prob = dist.log_prob(action)\n",
    "            entropy += dist.entropy().mean()\n",
    "\n",
    "            # related values are added to the arrays\n",
    "            log_probs.append(log_prob)\n",
    "            values.append(value)\n",
    "            rewards.append(torch.FloatTensor(reward).unsqueeze(1).to(device))\n",
    "            masks.append(torch.FloatTensor(1 - done).unsqueeze(1).to(device))\n",
    "\n",
    "            self.state = next_state\n",
    "\n",
    "            if np.any(done):    # for the given env, all the 20 environments terminate on the same frame\n",
    "                env_info = self.env.reset(train_mode=True)[self.brain]    # reset the env\n",
    "                self.state = env_info.vector_observations\n",
    "                # prepare return value, which is the mean of actual scores\n",
    "                ret = self.scores.mean()                      \n",
    "                self.scores = np.zeros(self.num_agents)       # reset scores\n",
    "\n",
    "        # state value of the last state is calculated using the neural network (model)\n",
    "\n",
    "        # print(\"entropy\", entropy)\n",
    "        # print(\"std\", self.model.log_std)\n",
    "\n",
    "        next_state = torch.FloatTensor(next_state).to(device)\n",
    "        _, next_value = self.model(next_state)\n",
    "\n",
    "        # using the prepared arrays, the return values are calculated\n",
    "        returns = self.compute_gae(next_value, rewards, masks, values)\n",
    "\n",
    "        # convert arrays to torch tensors\n",
    "        log_probs = torch.cat(log_probs)\n",
    "        returns = torch.cat(returns).detach()\n",
    "        values = torch.cat(values)\n",
    "\n",
    "        # calculate the advantage value\n",
    "        advantage = returns - values\n",
    "\n",
    "        # calculate actor loss (negative because of gradient ascend)\n",
    "        actor_loss = -(log_probs * advantage.detach()).mean()\n",
    "\n",
    "        # calculate critic loss\n",
    "        critic_loss = advantage.pow(2).mean()\n",
    "\n",
    "        # calculate total loss\n",
    "        loss = actor_loss + 0.5 * critic_loss - 0.001 * entropy\n",
    "\n",
    "        # calculate gradients and update the neural network (model)\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "\n",
    "        return ret\n",
    "\n",
    "    def act(self, state):\n",
    "        # given a state, returns the corresponding action\n",
    "\n",
    "        state = state / 10.0\n",
    "        state = torch.FloatTensor(state).to(device)\n",
    "        dist, value = self.model(state)  # the model returns a normal distribution for action value, and V(s)\n",
    "        # action is sampled from the distribution and clipped in range [-1, 1]\n",
    "        action = dist.sample().clamp(-1, 1)  \n",
    "        action_np = action.cpu().numpy()\n",
    "        return action_np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "entire-vancouver",
   "metadata": {},
   "source": [
    "### 4. Environment Sovler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "unique-hearts",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\tgoal_size -> 5.0\n",
      "\t\tgoal_speed -> 1.0\n",
      "Unity brain name: ReacherBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 33\n",
      "        Number of stacked Vector Observation: 1\n",
      "        Vector Action space type: continuous\n",
      "        Vector Action space size (per agent): 4\n",
      "        Vector Action descriptions: , , , \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of agents: 20\n",
      "Size of each action: 4\n",
      "Episode 100\tAverage Score: 4.7773448932\n",
      "Episode 200\tAverage Score: 30.5125293180\n",
      "Episode 212\tAverage Score: 32.0615792834"
     ]
    }
   ],
   "source": [
    "ENV_PATH = \"/home/fahim/Downloads/Reacher20_novis/Reacher.x86_64\"   # path to the reacher20 env\n",
    "SCORE_LIMIT = 32                              # mean score of 100 episodes to reach\n",
    "\n",
    "# initialize the environment\n",
    "env = UnityEnvironment(file_name=ENV_PATH)\n",
    "brain_name = env.brain_names[0]\n",
    "brain = env.brains[brain_name]\n",
    "\n",
    "# reset the environment\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "\n",
    "# number of agents\n",
    "num_agents = len(env_info.agents)\n",
    "print('Number of agents:', num_agents)\n",
    "\n",
    "# size of each action\n",
    "num_outputs = brain.vector_action_space_size\n",
    "print('Size of each action:', num_outputs)\n",
    "\n",
    "# examine the state space\n",
    "states = env_info.vector_observations\n",
    "num_inputs = states.shape[1]\n",
    "\n",
    "scores = []  # list containing scores from each episode\n",
    "scores_window = deque(maxlen=100)  # last 100 scores\n",
    "\n",
    "# create the ReacherAgent object\n",
    "agent = ReacherAgent(num_inputs, num_outputs, env, brain_name, num_agents)\n",
    "i_episode = 0\n",
    "\n",
    "while True:  # train until the SCORE_LIMIT is not reached\n",
    "    reward = agent.step()\n",
    "    if reward is not None:\n",
    "        scores.append(reward)\n",
    "        scores_window.append(reward)\n",
    "        score_mean_100 = np.mean(scores_window)\n",
    "        print('\\rEpisode {}\\tAverage Score: {:.10f}'.format(i_episode, score_mean_100), end=\"\")\n",
    "\n",
    "        if i_episode > 0 and i_episode % 100 == 0:\n",
    "            print()\n",
    "\n",
    "        # finish training once score limit is reached\n",
    "        if score_mean_100 > SCORE_LIMIT:\n",
    "            break\n",
    "\n",
    "        i_episode += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wooden-halifax",
   "metadata": {},
   "source": [
    "### 5. Rewards plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "japanese-scenario",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "plt.plot(np.arange(1, len(scores)+1), scores)\n",
    "plt.ylabel('Score')\n",
    "plt.xlabel('Episode #')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
